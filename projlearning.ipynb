{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import *\n",
    "from evaluate import *\n",
    "from main import *\n",
    "from load_glove import *\n",
    "from data_helpers import *\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 400000  words loaded!\n",
      "Normalizing word embeddings\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load word embeddings from glove file\n",
    "glove_file = \"/home/johannes/thesis_code/word_embeddings/glove.6B.100d.txt\"\n",
    "wiki_file = \"/home/johannes/thesis_code/word_embeddings/wiki-news-300d-1M.vec\"\n",
    "\n",
    "em = load_wiki_embeddings(wiki_file)\n",
    "#em = load_glove_embeddings(glove_file)\n",
    "normalize_embeddings(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  11779 positive training examples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create training triples\n",
    "data_file = \"/home/johannes/thesis_code/ml_experimentation/data/training/1A.english.training.data.txt\"\n",
    "gold_file = \"/home/johannes/thesis_code/ml_experimentation/data/training/1A.english.training.gold.txt\"\n",
    "train_data = read_train_examples(data_file, gold_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  8472  training examples with embeddings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace words with their embeddings, if they exist, otherwise remove the word from the training data\n",
    "\n",
    "train_embeddings = replace_with_embedding(train_data,em,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, iter:  -0.6849555489312252 0 \n",
      "\n",
      "Loss, iter:  -0.6585108950561535 1 \n",
      "\n",
      "Loss, iter:  -0.6451002617046965 2 \n",
      "\n",
      "Loss, iter:  -0.640563583494003 3 \n",
      "\n",
      "Loss, iter:  -0.6383220781102082 4 \n",
      "\n",
      "Loss, iter:  -0.6376534421241096 5 \n",
      "\n",
      "Loss, iter:  -0.6366217459225992 6 \n",
      "\n",
      "Loss, iter:  -0.6341735859727572 7 \n",
      "\n",
      "Loss, iter:  -0.6352474426727924 8 \n",
      "\n",
      "Loss, iter:  -0.6315837460022734 9 \n",
      "\n",
      "Loss, iter:  -0.6315030822422376 10 \n",
      "\n",
      "Loss, iter:  -0.6304586423455498 11 \n",
      "\n",
      "Loss, iter:  -0.6332151551805322 12 \n",
      "\n",
      "Loss, iter:  -0.6304534126899916 13 \n",
      "\n",
      "Loss, iter:  -0.6281163079699928 14 \n",
      "\n",
      "Loss, iter:  -0.6286124651481481 15 \n",
      "\n",
      "Loss, iter:  -0.6335166308954636 16 \n",
      "\n",
      "Loss, iter:  -0.6307477526255589 17 \n",
      "\n",
      "Loss, iter:  -0.6320487330812669 18 \n",
      "\n",
      "Loss, iter:  -0.6334276300448692 19 \n",
      "\n",
      "Loss, iter:  -0.6313140448466726 20 \n",
      "\n",
      "Loss, iter:  -0.6314328970254818 21 \n",
      "\n",
      "Loss, iter:  -0.6242069996220218 22 \n",
      "\n",
      "Loss, iter:  -0.6299476843181382 23 \n",
      "\n",
      "Loss, iter:  -0.6313661290800007 24 \n",
      "\n",
      "Loss, iter:  -0.6265305050141979 25 \n",
      "\n",
      "Loss, iter:  -0.628351166140118 26 \n",
      "\n",
      "Loss, iter:  -0.6231526850919434 27 \n",
      "\n",
      "Loss, iter:  -0.6226093148930256 28 \n",
      "\n",
      "Loss, iter:  -0.6231753535473745 29 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transforms,b = train(em,train_embeddings, 30, True,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  218753  words for testing\n"
     ]
    }
   ],
   "source": [
    "test_data_file = \"/home/johannes/thesis_code/ml_experimentation/data/testing/1A.english.vocabulary.txt\"\n",
    "#test_data_file = \"/home/johannes/thesis_code/ml_experimentation/data/training/1A.english.training.gold.txt\"\n",
    "te = read_test_examples(test_data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  67538  test examples with embeddings\n"
     ]
    }
   ],
   "source": [
    "word_embedding_pairs = add_embeddings(te,em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_only = [p[0] for p in word_embedding_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.4748973869008166, 'criminogenic', 9),\n",
       " (0.4751796511016147, 'fibre-optic', 11),\n",
       " (0.4754489519129972, 'banishing', 11),\n",
       " (0.4756956706835574, 'superfast', 23),\n",
       " (0.4757641252896167, 'ricer', 11),\n",
       " (0.4758433398455166, '2223', 11),\n",
       " (0.4765256974665763, 'zapping', 0),\n",
       " (0.4766350810536224, 'stop-and-search', 9),\n",
       " (0.4766882819960126, 'depo', 0),\n",
       " (0.47702572551791367, 'looping', 0),\n",
       " (0.47723573576045963, 'stationing', 11),\n",
       " (0.4781358665768441, '2137', 11),\n",
       " (0.47821285856341667, 'flashing', 0),\n",
       " (0.4791991949984561, 'postcode', 9),\n",
       " (0.47965572179860105, 'blighting', 11),\n",
       " (0.4803540333282047, 'profiling', 23),\n",
       " (0.48040719954982486, 'top-of-the-range', 9),\n",
       " (0.48058121974916984, 'intercountry', 9),\n",
       " (0.4808164539258804, 'clickstream', 9),\n",
       " (0.48986035683433177, 'dossier', 16)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract(em[\"volvo\"],words_only,em, transforms,b,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(b)\n",
    "transforms_ = [] #phi\n",
    "for i in range(k):\n",
    "    transforms_.append(np.identity(300) +np.random.normal(0, 0.5, [300,300]))\n",
    "\n",
    "p_ = [np.dot(transforms_[i],em[\"blackfly\"]).T for i in range(24)]\n",
    "p = [np.dot(transforms[i],em[\"blackfly\"]).T for i in range(24)]\n",
    "\n",
    "for i in range(k):\n",
    "    p[i] = p[i] / np.sqrt((np.sum(p[i]**2)))\n",
    "    p_[i] = p_[i] / np.sqrt((np.sum(p_[i]**2)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5612658686165467\n",
      "0.5301037162970009\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "s_ = np.dot(p_,em[\"insect\"])\n",
    "sigmoid_ = sigmoid(s_) \n",
    "rand_ = sigmoid_[np.argmax(sigmoid_)]\n",
    "\n",
    "\n",
    "s = np.dot(p,em[\"insect\"])\n",
    "sigmoid = sigmoid(s) \n",
    "gud = sigmoid[np.argmax(sigmoid)]\n",
    "print(rand_)\n",
    "print(gud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fak\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for q,h,t in train_embeddings:\n",
    "    if (list(q),list(h),t) == (list(em[\"pollution\"]),list(em[\"dirtiness\"]),1):\n",
    "        print(\"fak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"work\" in em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write projection matrices and bias to file\n",
    "\n",
    "matrix_fname = \"matrix\"\n",
    "bias_fname = \"bias\"\n",
    "\n",
    "matrix_file = open(matrix_fname, 'w+')\n",
    "np.array(transforms).tofile(matrix_file)\n",
    "matrix_file.close()\n",
    "\n",
    "bias_file = open(bias_fname, 'w+')\n",
    "np.array(b).tofile(bias_file)\n",
    "bias_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read projection matrices and bias from file\n",
    "matrix_fname = \"matrix\"\n",
    "bias_fname = \"bias\"\n",
    "\n",
    "matrix_file = open(matrix_fname, 'r')\n",
    "transforms = np.fromfile(matrix_file)\n",
    "\n",
    "bias_file = open(bias_fname, 'r')\n",
    "b = np.fromfile(bias_file)\n",
    "\n",
    "matrix_file.close()\n",
    "bias_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T E S T I N G  B O I S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([-1,1,2])\n",
    "h = np.array([1,2,1])\n",
    "phi = [np.array([[1.05,0.1,-0.1],[0.15,1.1,-0.05],[0.05,-0.1,0.95]]),np.array([[1.05,0.5,-0.1],[0.15,1.1,-0.05],[0.05,-0.1,0.95]])]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def normm(p):\n",
    "    p = p / np.sqrt((np.sum(p**2)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [np.dot(phi[i],q).T for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.50885454,  0.37610988,  0.77434386]),\n",
       " array([-0.40757786,  0.38362715,  0.82867997])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0] = normm(p[0])\n",
    "p[1] = normm(p[1])\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.dot(p,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01770908, 1.18835643])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoids = sigmoid(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73452612, 0.76644698])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxsim = np.argmax(sigmoids)\n",
    "y = sigmoids[maxsim]\n",
    "x = p[maxsim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5927593 ,  0.55792669,  1.20518755])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 0*np.log(y) - (np.subtract(1,0)*np.log(np.subtract(1,y)))\n",
    "gradient = np.dot(x.T,loss)\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_theta = phi[maxsim]\n",
    "#print(\"Before: \", prev_theta)\n",
    "phi[maxsim] = np.subtract(prev_theta, np.multiply(0.01,gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.05,  0.1 , -0.1 ],\n",
       "        [ 0.15,  1.1 , -0.05],\n",
       "        [ 0.05, -0.1 ,  0.95]]),\n",
       " array([[ 1.06719644,  0.48223391, -0.13743251],\n",
       "        [ 0.16719644,  1.08223391, -0.08743251],\n",
       "        [ 0.06719644, -0.11776609,  0.91256749]])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([1,2,2]) == np.array([1,2,2])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., -2., -5.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.gradient(np.array([1,2,3,4,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
